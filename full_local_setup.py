import sys
import os

try:
    from letta_client import Letta
    from letta import LLMConfig, EmbeddingConfig
    print("âœ… æˆåŠŸè¼‰å…¥ Letta çµ„ä»¶")
except ImportError as e:
    print(f"âŒ Import å¤±æ•—: {e}")
    sys.exit(1)

def setup_xiaowan_agent():
    host_ip = "192.168.1.252"
    print(f"ğŸ”Œ æ­£åœ¨é€£æ¥ Letta Server (http://{host_ip}:8283)...")
    client = Letta(base_url=f"http://{host_ip}:8283")

    # 1. é…ç½®å®šç¾©
    qwen_config = LLMConfig(
        model="qwen3-next-80b",
        model_endpoint=f"http://{host_ip}:8607/v1",
        model_wrapper="chatml",
        context_window=128000,
        model_endpoint_type="openai" 
    )

    bgem3_config = EmbeddingConfig(
        embedding_endpoint_type="openai", 
        embedding_endpoint=f"http://{host_ip}:8602", 
        embedding_model="BAAI/bge-m3",
        embedding_dim=1024
    )

    system_prompt = (
        "èº«ä»½ï¼šä½ å«ã€Œå°ä¸¸ã€ï¼Œä¿‚ä¸€ä½å¾—åŠ›åŠ©æ‰‹ã€‚\n"
        "èªè¨€/é¢¨æ ¼ï¼šå…¨ç¨‹ä½¿ç”¨åœ°é“é¦™æ¸¯å»£æ±è©±ï¼Œèªæ°£æ´»æ½‘ã€è¦ªåˆ‡ã€å°ˆæ¥­ã€‚è¬›å˜¢ç°¡çŸ­ç›´æ¥ã€‚\n"
        "èª å¯¦ï¼šè­˜å°±è­˜ï¼Œå””è­˜å°±æŸ¥è¨˜æ†¶ï¼ŒæŸ¥å””åˆ°å°±è©±å””çŸ¥ã€‚\n"
        "å¯« Codeï¼šå¦‚æœæœ‰ç¨‹å¼ç¢¼éœ€è¦ä¿®æ”¹ï¼Œå¿…é ˆè²¼å‡ºæ•´å€‹ file å˜…å®Œæ•´ source codeï¼Œå””å¥½æ·¨ä¿‚è¬›æ”¹å’—é‚Šåº¦ã€‚\n"
        "æä¾›æ–¹æ¡ˆï¼šå…ˆç•€ä¸€å€‹ç°¡è¦å˜…æ–¹æ¡ˆç¸½çµã€‚è©³ç´°æ­¥é©Ÿè¦ä¸€æ­¥ä¸€æ­¥ç•€ï¼Œç­‰æˆ‘ç¢ºèªæˆ–è€…å•å®Œå…ˆå†ç•€ä¸‹ä¸€æ­¥ï¼Œå””å¥½ä¸€æ¬¡éæ‰æ™’å‡ºåšŸã€‚"
    )

    print("ğŸš€ æ­£åœ¨å•Ÿå‹•/æ›´æ–°æœ¬åœ° Agentã€Œå°ä¸¸ã€...")
    
    try:
        agents = client.agents.list()
        my_agent = next((a for a in agents if a.name == "å°ä¸¸"), None)
        
        if my_agent:
            print(f"ğŸ“¢ æµåˆ°ç¾æœ‰å˜…ã€Œå°ä¸¸ã€(ID: {my_agent.id})ï¼Œæ­£åœ¨åŒæ­¥æœ€æ–°é…ç½®...")
            client.agents.update(
                agent_id=my_agent.id,
                llm_config=qwen_config,
                embedding_config=bgem3_config,
                system=system_prompt
            )
        else:
            my_agent = client.agents.create(
                name="å°ä¸¸",
                llm_config=qwen_config,
                embedding_config=bgem3_config,
                system=system_prompt
            )
            print(f"âœ… æˆåŠŸå»ºç«‹æ–° Agentï¼ID: {my_agent.id}")

        # 2. å‚³é€è¨Šæ¯
        print("\nğŸ’¬ æ­£åœ¨å‚³é€æ¸¬è©¦è¨Šæ¯...")
        response = client.agents.messages.create(
            agent_id=my_agent.id,
            messages=[{
                "role": "user",
                "content": "å°ä¸¸ä½ å¥½ï¼å®œå®¶é€£ç·šæˆåŠŸå–‡ï¼Œè©¦ä¸‹ç”¨ä½ å˜…é¢¨æ ¼åŒæˆ‘æ‰“å€‹æ‹›å‘¼ã€‚"
            }]
        )
        
        # 3. å¼·åŒ–ç‰ˆè¨Šæ¯è§£æ (é˜²æ­¢ 'ToolCallMessage' å ±éŒ¯)
        print("\nğŸ¤– å°ä¸¸å›è¦†ï¼š")
        if response and hasattr(response, 'messages'):
            for msg in response.messages:
                # åˆ¤æ–·è¨Šæ¯é¡å‹ä¸¦å®‰å…¨ç²å–å…§å®¹
                msg_type = type(msg).__name__
                
                # Assistant ç›´æ¥å›è¦†
                if msg_type == "AssistantMessage" and hasattr(msg, 'content'):
                    if msg.content:
                        print(f"{msg.content}")
                
                # æ€è€ƒéç¨‹ (Internal Thoughts)
                elif hasattr(msg, 'internal_monologue') and msg.internal_monologue:
                    # å¦‚æœä½ æƒ³ç‡ä½¢è«—ç·Šä¹œï¼Œå¯ä»¥ print å‡ºåšŸ
                    # print(f"(æ€è€ƒä¸­: {msg.internal_monologue})")
                    pass
                
                # è™•ç† Tool Call æˆ–å…¶ä»–ç‰¹æ®Šç‰©ä»¶ (é¿å…å ±éŒ¯)
                elif msg_type == "ToolCallMessage":
                    # print(f"ğŸ”§ [å°ä¸¸æº–å‚™è¡Œ Tool: {getattr(msg, 'tool_call', 'unknown')}]")
                    pass

    except Exception as e:
        print(f"âŒ é‹è¡Œæ™‚å‡ºéŒ¯ï¼š{str(e)}")

if __name__ == "__main__":
    setup_xiaowan_agent()