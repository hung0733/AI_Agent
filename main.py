# main.py
import io
import httpx
import uvicorn
import json
import base64
from fastapi import FastAPI, UploadFile, File, Form, Request, HTTPException
from fastapi.responses import StreamingResponse
from PIL import Image
from server_conf import Config

class LocalAIProxy:
    def __init__(self):
        self.app = FastAPI(title="Local AI Chain Proxy (Full Integrated)")
        self.client = httpx.AsyncClient(timeout=None)
        self.setup_routes()

    def setup_routes(self):
        """é‡æ–°æ›è¼‰æ‰€æœ‰ Endpointï¼Œç¢ºä¿ STT/TTS æ¢å¾©é‹ä½œ"""
        self.app.get("/v1/models")(self.get_models)
        self.app.post("/v1/chat/completions")(self.chat_completions)
        self.app.post("/v1/audio/transcriptions")(self.speech_to_text)
        self.app.post("/v1/audio/speech")(self.text_to_speech)

    async def get_models(self):
        return {"object": "list", "data": Config.AVAILABLE_MODELS}

    # --- é—œéµï¼š[å¹´æœˆæ—¥æ™‚åˆ†ç§’][æ–‡å­—] æ•¸æ“šæ”¶é›†èˆ‡ 80B ç³¾éŒ¯ ---
    async def _fix_and_save_speech(self, raw_audio_bytes, raw_text):
        """å‚³é€è‡³ V100 Server é€²è¡Œç³¾éŒ¯ï¼Œä¸¦æœ¬åœ°å„²å­˜"""
        # ä½¿ç”¨ Qwen-80B (V100 Server) é€²è¡Œå»£æ±è©±ç³¾éŒ¯
        fix_prompt = f"ç”¨æˆ¶ç™¼éŸ³å””æ¸…ï¼Œè«‹æ ¹æ“šå»£æ±è©±èªå¢ƒä¿®æ­£éŒ¯å­—ï¼Œåªéœ€è¼¸å‡ºä¿®æ­£å¾Œçš„å»£æ±è©±æ–‡å­—ï¼š\n{raw_text}"
        
        try:
            # å°„å» 80B å¤§è…¦æ‰€åœ¨çš„ä¼ºæœå™¨
            resp = await self.client.post(Config.URL_TEXT, json={
                "model": Config.MODEL_TEXT,
                "messages": [{"role": "user", "content": fix_prompt}],
                "stream": False
            })
            fixed_text = resp.json()["choices"][0]["message"]["content"].strip()
            
            # æª”åæ ¼å¼: [20260221215508][ä½ å¥½å‘€]
            timestamp = time.strftime("%Y%m%d%H%M%S")
            # ç§»é™¤æª”åä¸åˆæ³•å­—å…ƒ
            safe_text = "".join([c for c in fixed_text if c.isalnum() or c in " "]).strip()
            filename_base = f"[{timestamp}][{safe_text}]"
            
            # å„²å­˜åˆ° 3090 é€™éƒ¨æ©Ÿçš„æœ¬åœ°ç¡¬ç¢Ÿ
            with open(os.path.join("training_data", f"{filename_base}.mp3"), "wb") as f:
                f.write(raw_audio_bytes)
            with open(os.path.join("training_data", f"{filename_base}.txt"), "w", encoding="utf-8") as f:
                f.write(fixed_text)
            
            print(f"ğŸ’¾ [SAVED TO DATASET] {filename_base}")
            return fixed_text
        except Exception as e:
            print(f"âš ï¸ ç³¾éŒ¯å¤±æ•—: {e}")
            return raw_text

    async def speech_to_text(self, file: UploadFile = File(...)):
        audio_content = await file.read()
        # 3090 ä¸Šçš„ Faster Whisper
        files = {"file": (file.filename, audio_content, file.content_type)}
        resp = await self.client.post(Config.URL_WHISPER, files=files, data={"model": "large-v3"})
        raw_text = resp.json().get("text", "")
        
        # å‘¼å« V100 ä¸Šçš„ 80B åŸ·å­—ä¸¦å„²å­˜
        fixed_text = await self._fix_and_save_speech(audio_content, raw_text)
        return {"text": fixed_text}

    async def text_to_speech(self, request: Request):
        try:
            body = await request.json()
            input_text = body.get("input", "")
            print(f"ğŸ”Š [TTS] æ”¶åˆ°èªéŸ³è«‹æ±‚: {input_text[:30]}...")
            
            body["model"] = Config.MODEL_MAPPING.get(body.get("model", "tts-1"), "piper-high-quality")
            
            async def audio_stream():
                async with self.client.stream("POST", Config.URL_TTS, json=body) as r:
                    async for chunk in r.aiter_bytes():
                        yield chunk

            return StreamingResponse(audio_stream(), media_type="audio/mpeg")
        except Exception as e:
            print(f"âŒ [TTS ERROR]: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    def _resize_image_if_needed(self, base64_image_str):
        """åœ–ç‰‡è‡ªå‹•ç¸®æ”¾è‡³ 1080p é‚è¼¯"""
        try:
            header, encoded = base64_image_str.split(",", 1)
            img_data = base64.b64decode(encoded)
            img = Image.open(io.BytesIO(img_data))
            
            orig_w, orig_h = img.size
            max_w, max_h = 1920, 1080

            if orig_w > max_w or orig_h > max_h:
                print(f"ğŸ“ [RESIZE] åœ–ç‰‡å¤ªå¤§ ({orig_w}x{orig_h}) -> ç¸®æ”¾è‡³ 1080p")
                ratio = min(max_w / orig_w, max_h / orig_h)
                new_size = (int(orig_w * ratio), int(orig_h * ratio))
                img = img.resize(new_size, Image.LANCZOS)
                
                buffered = io.BytesIO()
                img.save(buffered, format="JPEG", quality=90)
                new_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
                return f"{header},{new_base64}"
            return base64_image_str
        except Exception as e:
            print(f"âš ï¸ [RESIZE WARNING] ç¸®æ”¾å¤±æ•—: {e}")
            return base64_image_str

    def _extract_user_text(self, messages):
        for msg in reversed(messages):
            if msg["role"] == "user":
                content = msg.get("content")
                if isinstance(content, str): return content
                if isinstance(content, list):
                    for item in content:
                        if item.get("type") == "text": return item.get("text")
        return "(å†‡æ–‡å­—è¼¸å…¥)"

    # --- æ ¸å¿ƒé€£é–åˆ†æ ---

    async def _get_vision_description(self, messages):
        print("\n" + "ğŸ“¸" * 20 + "\n [PHASE 1] è¦–è¦ºåˆ†æé€²è¡Œä¸­...")
        
        # ç¸®æ”¾è™•ç†
        for msg in messages:
            if msg["role"] == "user" and isinstance(msg["content"], list):
                for item in msg["content"]:
                    if item["type"] == "image_url":
                        url_val = item["image_url"]["url"]
                        if url_val.startswith("data:image"):
                            item["image_url"]["url"] = self._resize_image_if_needed(url_val)

        vision_body = {"model": Config.MODEL_VISION, "messages": messages, "stream": False}
        
        # æ³¨å…¥åˆ†ææŒ‡ä»¤
        for msg in vision_body["messages"]:
            if msg["role"] == "user" and isinstance(msg["content"], list):
                for item in msg["content"]:
                    if item["type"] == "text":
                        item["text"] = f"{Config.VISION_PROMPT_PREFIX}\n{item['text']}"
        
        resp = await self.client.post(Config.URL_VISION, json=vision_body)
        description = resp.json()["choices"][0]["message"]["content"]
        
        print(f"\nğŸ“ [VISION NOTES]:\n{description}\n")
        print("ğŸ“¸" * 20)
        return description

    async def chat_completions(self, request: Request):
        try:
            body = await request.json()
            messages = body.get("messages", [])
            is_streaming = body.get("stream", False)

            user_text = self._extract_user_text(messages)
            print("\n" + "ğŸ’¬" * 20)
            print(f" ğŸ‘¤ USER INPUT: {user_text}")

            has_image = any(isinstance(m.get("content"), list) and any(i.get("type") == "image_url" for i in m["content"]) for m in messages)

            if has_image:
                description = await self._get_vision_description(messages)
                new_prompt = f"ã€è¦–è¦ºç­†è¨˜ã€‘\n{description}\n\nã€ç”¨æˆ¶åŸå§‹å•é¡Œã€‘\n{user_text}"
                body["messages"] = [{"role": "user", "content": new_prompt}]
                body["model"] = Config.MODEL_TEXT
                target_url = Config.URL_TEXT
                print(f" ğŸ§  [ROUTE] çµåˆè¦–è¦ºï¼Œç™¼é€è‡³ 80B")
            else:
                body["model"] = Config.MODEL_TEXT
                target_url = Config.URL_TEXT
                print(f" ğŸ§  [ROUTE] ç´”æ–‡å­—ï¼Œç™¼é€è‡³ 80B")
            
            print("ğŸ’¬" * 20 + "\n")

            if is_streaming:
                async def stream_generator():
                    async with self.client.stream("POST", target_url, json=body) as r:
                        async for line in r.aiter_lines():
                            if line: yield f"{line}\n\n"
                return StreamingResponse(stream_generator(), media_type="text/event-stream")
            else:
                resp = await self.client.post(target_url, json=body)
                return resp.json()

        except Exception as e:
            print(f"âŒ [PROXY ERROR]: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    def run(self):
        print(f"ğŸš€ Proxy Server å•Ÿå‹•! ç›£è½ Port: {Config.SERVER_PORT}")
        uvicorn.run(self.app, host=Config.SERVER_HOST, port=Config.SERVER_PORT)

if __name__ == "__main__":
    LocalAIProxy().run()