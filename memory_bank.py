import time
import requests
import uuid
import global_var
from qdrant_client import QdrantClient
from qdrant_client.http import models



class MemoryBank:
    def __init__(self):
        # 1. åˆå§‹åŒ–æ™‚ç›´æ¥é€£æ¥ä¸¦æª¢æŸ¥ Collections
        try:
            self.client = QdrantClient(
                host=global_var.PORTS["QDRANT"]["host"], 
                port=global_var.PORTS["QDRANT"]["port"]
            )
            self._ensure_collections()
            print("âœ… å°ä¸¸è¨˜æ†¶åº«å·²é€£æ¥", flush=True)
        except Exception as e:
            print(f"âŒ è¨˜æ†¶åº«é€£æ¥å¤±æ•—: {e}", flush=True)
            self.client = None

    def _ensure_collections(self):
        """(ç§æœ‰æ–¹æ³•) ç¢ºä¿æ‰€éœ€çš„ Collection å­˜åœ¨"""
        if not self.client: return
        try:
            collections = {"trinity_knowledge": 1024, "chat_memory": 1024}
            existing = [c.name for c in self.client.get_collections().collections]
            for name, dim in collections.items():
                if name not in existing:
                    self.client.create_collection(
                        name, 
                        vectors_config=models.VectorParams(size=dim, distance=models.Distance.COSINE)
                    )
        except: pass

    def _get_dify_context(self, query_text):
        """
        æ ¹æ“š Dify å®˜æ–¹å›å‚³çµæ§‹è§£æçŸ¥è­˜åº«å…§å®¹
        """
        # 1. åŸºæœ¬é…ç½® (è«‹ç¢ºä¿ dataset_id æ­£ç¢º)
        DIFY_API_KEY = "dataset-JbnVJj7QfATRC9L8OqbZCB1U"
        DATASET_ID = "949aa016-3dff-45e3-9f9a-0298b19ef304"

        DIFY_URL = f"http://localhost/v1/datasets/{DATASET_ID}/retrieve"
        
        headers = {
            "Authorization": f"Bearer {DIFY_API_KEY}",
            "Content-Type": "application/json"
        }

        # 2. æª¢ç´¢åƒæ•¸ (å°æ¨™ä½ æä¾›çš„ Retrieve æ ¼å¼)
        payload = {
            "query": query_text,
            "retrieval_model": {
                "search_method": "hybrid_search",
                "reranking_enable": False, # ğŸ‘ˆ è¨­ç‚º False
                "top_k": 5,
                "weights": 0.5, # å‘é‡èˆ‡é—œéµå­—å„ä½”ä¸€åŠæ¬Šé‡
                "score_threshold_enabled": False
            }
        }

        try:
            resp = requests.post(DIFY_URL, json=payload, headers=headers, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                records = data.get('records', [])
                
                parts = []
                for rec in records:
                    # ğŸ’¡ é‡é»ä¿®æ­£ï¼šæ ¹æ“šä½ æä¾›çš„ JSON çµæ§‹ï¼Œå…§å®¹åœ¨ segment å…§
                    segment = rec.get('segment', {})
                    text_content = segment.get('content', '')
                    
                    if text_content:
                        # ç²å–æª”æ¡ˆä¾†æºåç¨± (å¦‚æœæœ‰)
                        doc_name = segment.get('document', {}).get('name', 'çŸ¥è­˜åº«æ–‡æª”')
                        parts.append(f"ã€åƒè€ƒä¾†æº: {doc_name}ã€‘\n{text_content}")
                
                return "\n\n".join(parts) if parts else ""
            else:
                print(f"âš ï¸ Dify æª¢ç´¢å¤±æ•—: {resp.status_code} - {resp.text}", flush=True)
                return ""
        except Exception as e:
            print(f"âŒ Dify é€£ç·šç•°å¸¸: {e}", flush=True)
            return ""

    def _get_vector(self, text):
        """(ç§æœ‰æ–¹æ³•) å–å¾—æ–‡å­—çš„å‘é‡"""
        if not text: return []
        payload = {"input": text, "model": global_var.MODELS["EMBED"]}
        try:
            try:
                resp = requests.post(global_var.PORTS["EMBED"], json=payload, timeout=5)
                resp.raise_for_status()
            except:
                fallback = global_var.PORTS["EMBED"].replace("/embeddings", "/v1/embeddings")
                resp = requests.post(fallback, json=payload, timeout=5)
            data = resp.json()
            if 'data' in data: return data['data'][0]['embedding']
            if isinstance(data, list): return data[0]['embedding']
            return []
        except: return []
        
    def get_context(self, query_text):
        """æ•´åˆæ‰€æœ‰ä¾†æºçš„ä¸Šä¸‹æ–‡"""
        if not query_text: return []
        print(f"ğŸ” å°ä¸¸å›æ†¶ä¸­...", flush=True)

        parts = []
        
        # 1. å…ˆå» Dify æ‰¾å°ˆæ¥­çŸ¥è­˜
        dify_knowledge = self._get_dify_context(query_text)
        if dify_knowledge:
            parts.append(f"ã€å°ˆæ¥­çŸ¥è­˜åº«åƒè€ƒè³‡æ–™ã€‘ï¼š\n{dify_knowledge}")
            
        # 2. å†æ‰¾æœ¬åœ° Qdrant çš„å°è©±å›æ†¶ (chat_memory)
        if self.client:
            vec = self._get_vector(query_text)
            if vec:
                try:
                    h = self.client.search(collection_name="chat_memory", query_vector=vec, limit=2)
                    mem = "\n".join([f"- {r.payload.get('content')}" for r in h if r.score > 0.5])
                    if mem:
                        parts.append(f"ã€éå¾€å°è©±å›æ†¶ã€‘ï¼š\n{mem}")
                except: pass
        
        return "\n\n".join(parts) if parts else ""

    def save_memory(self, q, a):
        """å„²å­˜ä¸¦ç¸½çµè¨˜æ†¶"""
        if not self.client: return
        prompt = f"æ‘˜è¦å°è©±é‡é»ã€‚è‹¥æ˜¯é–’èŠ/æ‰“æ‹›å‘¼/å»¢è©±ï¼Œåªå› SKIPã€‚è‹¥æ˜¯é‡è¦è³‡è¨Š/è¨­å®š/æŠ€è¡“æ•™å­¸ï¼Œè«‹ç¸½çµã€‚\nå•ï¼š{q}\nç­”ï¼š{a}"
        
        try:
            resp = requests.post(global_var.PORTS["15B"], json={
                "model": global_var.MODELS["15B"],
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.1, "max_tokens": 100
            }, timeout=5)
            summary = resp.json()['choices'][0]['message']['content'].strip()
            
            if "SKIP" not in summary.upper() and len(summary) > 5:
                vec = self._get_vector(summary)
                if vec:
                    self.client.upsert(
                        collection_name="chat_memory",
                        points=[models.PointStruct(
                            id=str(uuid.uuid4()), # å·²æ”¹ç”¨ UUID
                            vector=vec,
                            payload={"content": summary, "time": time.ctime()}
                        )]
                    )
                print(f"ğŸ’¾ å¯«å…¥è¨˜æ†¶: {summary[:20]}...", flush=True)
        except: pass
        
    def add_to_knowledge(self, text, metadata=None):
        """
        å°‡ Web Client å‚³ä¾†çš„çŸ¥è­˜å­˜å…¥ trinity_knowledge
        """
        if not self.client: return 0
        
        # 1. æ–‡æœ¬åˆ‡ç‰‡ (Chunking)
        chunk_size = 500
        overlap = 50
        chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size - overlap)]
        
        points = []
        for chunk in chunks:
            if not chunk.strip(): continue
            
            # 2. ä½¿ç”¨ç§æœ‰æ–¹æ³• _get_vector å–å¾—å‘é‡
            vector = self._get_vector(chunk)
            if not vector: continue
            
            # 3. å°è£ Point
            points.append(models.PointStruct(
                id=str(uuid.uuid4()),
                vector=vector,
                payload={
                    "text": chunk,  # ğŸ‘ˆ é€™è£¡å¿…é ˆç”¨ 'text'ï¼Œå› ç‚º get_context æ˜¯æŠ“é€™å€‹æ¬„ä½
                    "metadata": metadata or {},
                    "source": "web_upload",
                    "timestamp": time.time()
                }
            ))
        
        # 4. æ‰¹é‡å¯«å…¥ Qdrant
        if points:
            self.client.upsert(
                collection_name="trinity_knowledge",
                points=points
            )
            print(f"ğŸ“š çŸ¥è­˜å…¥åº«æˆåŠŸ: å¢åŠ äº† {len(points)} å€‹å€å¡Š", flush=True)
            return len(points)
        return 0