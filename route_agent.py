import time
import requests
import json
import global_var
from memory_bank import MemoryBank

class RouteAgent:
    def __init__(self):
        # å¯¦ä¾‹åŒ–æ™‚è‡ªå‹•ç¶å®šä¸€å€‹è¨˜æ†¶åº«
        self.mb = MemoryBank()
    
    def determine_difficulty(self, user_input):
        gatekeeper_prompt = f"""
        ä½ æ˜¯ AI è·¯ç”±åˆ†é¡å“¡ã€‚è«‹åˆ†æç”¨æˆ¶è¼¸å…¥ï¼Œåš´æ ¼åˆ¤æ–·æ˜¯å¦éœ€è¦ã€Œåšå£«ç´šã€æ¨¡å‹è™•ç†ã€‚
        
        ã€HARD æ¨™æº–ã€‘(å¿…é ˆç¬¦åˆï¼Œå¦å‰‡ä¸é¸):
        1. æ·±åº¦é‚è¼¯æ¨ç† (Deep Logic / Paradox)
        2. è¤‡é›œæ¶æ§‹è¨­è¨ˆ (Complex Architecture)
        3. æ·±åº¦æ•¸å­¸/ç‰©ç†æ¨å° (Math / Physics)
        4. å“²å­¸/å€«ç†æ·±åº¦æ€è€ƒ (Philosophy)
        5. å‰µæ„å¯«ä½œ (Novel / Script)

        ã€MEDIUM æ¨™æº–ã€‘:
        - Coding, Translation, Explanation, General Q&A

        ã€EASY æ¨™æº–ã€‘:
        - Greeting, Chit-chat, Simple Fact

        User: "{user_input}"
        Output ONLY: EASY, MEDIUM, or HARD.
        """
        try:
            resp = requests.post(
                global_var.PORTS["15B"],
                json={"model": global_var.MODELS["15B"], "messages": [{"role": "user", "content": gatekeeper_prompt}], "temperature": 0.1, "max_tokens": 5},
                timeout=5
            )
            level = resp.json()['choices'][0]['message']['content'].strip().upper()
            if "HARD" in level: return "HARD"
            if "MEDIUM" in level: return "MEDIUM"
            return "EASY"
        except:
            return "MEDIUM"
    
    def route_question(self, user_input, allowDeepThink=False):
        # 1. é€²å…¥æ€è€ƒå€å¡Š
        yield "<thinking>\n"
        yield "ğŸ” æ­£åœ¨åˆ†æå•é¡Œè¤‡é›œåº¦èˆ‡æª¢ç´¢çŸ¥è­˜åº«...\n"
        
        # æª¢ç´¢èˆ‡é›£åº¦åˆ¤æ–· (é€™å…©æ­¥ç¾åœ¨æ˜¯é˜»å¡çš„ï¼Œä½†å‰ç«¯å·²ç¶“æ”¶åˆ°ä¸Šé¢çš„å­—äº†)
        context = self.mb.get_context(user_input)
        difficulty = self.determine_difficulty(user_input)
        
        yield f"âœ… è·¯ç”±åˆ¤å®šï¼š{difficulty}\n"
        yield f"ğŸ“š çŸ¥è­˜åº«æª¢ç´¢å®Œæˆ\n"
        yield f"å•Ÿå‹•å¤§è…¦ä¸­...\n"
        yield "</thinking>\n\n" # çµæŸæ€è€ƒå€å¡Šï¼Œæº–å‚™è¼¸å‡ºæ­£æ–‡
        
        config = {
            "HARD": (global_var.PORTS["80B"], global_var.MODELS["80B"], 900, "\n(ç•¶å‰æ¨¡å¼ï¼šæ·±åº¦æ€è€ƒ)"),
            "MEDIUM": (global_var.PORTS["30B"], global_var.MODELS["30B"], 150, ""),
            "EASY": (global_var.PORTS["15B"], global_var.MODELS["15B"], 30, "")
        }
        
        active_level = "MEDIUM" if (difficulty == "HARD" and not allowDeepThink) else difficulty
        target_url, target_model, timeout_val, extra_prompt = config[active_level][:4]
        
        payload = {
            "model": target_model,
            "messages": [
                {"role": "system", "content": global_var.SYSTEM_PROMPT + extra_prompt},
                {"role": "user", "content": f"ã€èƒŒæ™¯è³‡æ–™ã€‘ï¼š\n{context}\n\nã€ç”¨æˆ¶å•é¡Œã€‘ï¼š{user_input}"}
            ],
            "temperature": 0.7,
            "stream": True 
        }

        full_answer = []
        print(f"ğŸ“¡ æ­£åœ¨è«‹æ±‚æ¨¡å‹: {target_model} @ {target_url}", flush=True)

        try:
            with requests.post(target_url, json=payload, timeout=timeout_val, stream=True) as resp:
                print(f"ğŸ“¥ æ¨¡å‹å›æ‡‰ç‹€æ…‹ç¢¼: {resp.status_code}", flush=True)
                
                for line in resp.iter_lines():
                    if not line:
                        continue
                    
                    line_text = line.decode("utf-8").strip()
                    # ğŸ”´ åµéŒ¯ç”¨ï¼šå°å‡ºåŸå§‹è¡Œæ•¸æ“š
                    # print(f"DEBUG RAW LINE: {line_text}", flush=True)

                    if line_text.startswith("data: "):
                        data_str = line_text[6:].strip()
                        if data_str == "[DONE]":
                            break
                        
                        try:
                            data_json = json.loads(data_str)
                            # ğŸ’¡ é—œéµæª¢æŸ¥ï¼šæœ‰å•²æ¨¡å‹ delta å…¥é¢ä¿‚ 'text' è€Œå””ä¿‚ 'content'
                            choices = data_json.get('choices', [{}])
                            delta = choices[0].get('delta', {})
                            
                            # å…¼å®¹ä¸åŒæ¨¡å‹çš„æ¬„ä½å
                            chunk = delta.get('content') or delta.get('text') or ""
                            
                            if chunk:
                                full_answer.append(chunk)
                                yield chunk
                        except Exception as e:
                            print(f"âš ï¸ JSON è§£æå¤±æ•—: {e} | åŸæ–‡: {data_str}", flush=True)
                            continue
            
            if full_answer:
                self.mb.save_memory(user_input, "".join(full_answer))
        except Exception as e:
            print(f"âŒ ä¸²æµç™¼ç”Ÿç•°å¸¸: {e}", flush=True)
            yield f"âŒ ç³»çµ±é€£ç·šç•°å¸¸: {str(e)}"