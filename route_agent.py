import time
import requests
import global_var

from memory_bank import MemoryBank

class RouteAgent:
    _mb = None

    @classmethod
    def get_mb(cls):
        if cls._mb is None:
            cls._mb = MemoryBank()
        return cls._mb
    
    @staticmethod
    def determine_difficulty(user_input):
        gatekeeper_prompt = f"""
        ä½ æ˜¯ AI è·¯ç”±åˆ†é¡å“¡ã€‚è«‹åˆ†æç”¨æˆ¶è¼¸å…¥ï¼Œåš´æ ¼åˆ¤æ–·æ˜¯å¦éœ€è¦ã€Œåšå£«ç´šã€æ¨¡å‹è™•ç†ã€‚
        
        ã€HARD æ¨™æº–ã€‘(å¿…é ˆç¬¦åˆï¼Œå¦å‰‡ä¸é¸):
        1. æ·±åº¦é‚è¼¯æ¨ç† (Deep Logic / Paradox)
        2. è¤‡é›œæ¶æ§‹è¨­è¨ˆ (Complex Architecture)
        3. æ·±åº¦æ•¸å­¸/ç‰©ç†æ¨å° (Math / Physics)
        4. å“²å­¸/å€«ç†æ·±åº¦æ€è€ƒ (Philosophy)
        5. å‰µæ„å¯«ä½œ (Novel / Script)

        ã€MEDIUM æ¨™æº–ã€‘:
        - Coding, Translation, Explanation, General Q&A

        ã€EASY æ¨™æº–ã€‘:
        - Greeting, Chit-chat, Simple Fact

        User: "{user_input}"
        Output ONLY: EASY, MEDIUM, or HARD.
        """
        try:
            resp = requests.post(
                global_var.PORTS["15B"],
                json={"model": global_var.MODELS["15B"], "messages": [{"role": "user", "content": gatekeeper_prompt}], "temperature": 0.1, "max_tokens": 5},
                timeout=5
            )
            level = resp.json()['choices'][0]['message']['content'].strip().upper()
            if "HARD" in level: return "HARD"
            if "MEDIUM" in level: return "MEDIUM"
            return "EASY"
        except:
            return "MEDIUM"
    
    @staticmethod
    def route_question(user_input, allowDeepThink = False):
        mb = RouteAgent.get_mb()
        
        # 1. æª¢ç´¢ RAG ä¸Šä¸‹æ–‡
        context = mb.get_context(user_input)
        
        # 2. åˆ¤æ–·é›£åº¦
        difficulty = RouteAgent.determine_difficulty(user_input)
        
        # 3. æ±ºå®šè·¯ç”±åƒæ•¸ (é€™è£¡å¯ä»¥é‡æ§‹æˆä¸€å€‹ Dict æ˜ å°„è¡¨ï¼Œæ›´å„ªé›…)
        config = {
            "HARD": (global_var.PORTS["80B"], global_var.MODELS["80B"], 900, "\n(ç•¶å‰æ¨¡å¼ï¼šæ·±åº¦æ€è€ƒã€‚è«‹æä¾›æ¥µå…·é‚è¼¯æ€§ã€çµæ§‹åš´è¬¹ã€æœ‰æ·±åº¦çš„è©³ç´°å›ç­”ã€‚)", "ğŸ“ å¬å–š 80B åšå£«..."),
            "MEDIUM": (global_var.PORTS["30B"], global_var.MODELS["30B"], 150, "", "âš¡ ä½¿ç”¨ 30B ä¸»è…¦..."),
            "EASY": (global_var.PORTS["15B"], global_var.MODELS["15B"], 30, "", "ğŸ‡ ä½¿ç”¨ 1.5B å¿«é€Ÿå›æ‡‰...")
        }
        
        # å¦‚æœ HARD ä½†ä¸å…è¨± DeepThinkï¼Œè‡ªå‹•é™ç´šåˆ° MEDIUM
        active_level = difficulty
        if difficulty == "HARD" and not allowDeepThink:
            active_level = "MEDIUM"
            
        target_url, target_model, timeout_val, extra_prompt, msg = config[active_level]
        
        sys_prompt = global_var.SYSTEM_PROMPT + extra_prompt
        
        print(msg, flush=True)

        # åŸ·è¡Œç”Ÿæˆ
        payload = {
            "model": target_model,
            "messages": [
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": f"ã€èƒŒæ™¯è³‡æ–™ã€‘ï¼š\n{context}\n\nã€ç”¨æˆ¶å•é¡Œã€‘ï¼š{user_input}"}
            ],
            "temperature": 0.7
        }

        try:
            start_t = time.time()
            # ç™¼é€è«‹æ±‚
            resp = requests.post(target_url, json=payload, timeout=timeout_val)
            
            if resp.status_code != 200:
                raise Exception(f"Status {resp.status_code}")
                
            answer = resp.json()['choices'][0]['message']['content']
            duration = time.time() - start_t
            
            # è¨ˆç®—ç”Ÿæˆé€Ÿåº¦ (ä¼°ç®—)
            speed = len(answer) / duration if duration > 0 else 0
            print(f"âœ… ç”Ÿæˆå®Œç•¢ (è€—æ™‚: {duration:.1f}s | é€Ÿåº¦: ~{speed:.1f} chars/s)", flush=True)
            
            mb.save_memory(user_input, answer)
            return answer

        except Exception as e:
            print(f"âŒ {target_model} é€£æ¥å¤±æ•—/è¶…æ™‚: {e}", flush=True)
            
            if difficulty == "HARD":
                print(f"ğŸ”„ 80B å¤ªæ…¢/ç„¡åæ‡‰ï¼Œå˜—è©¦åˆ‡æ›å› 30B æ•‘å ´...", flush=True)
                try:
                    payload["model"] = global_var.MODELS["30B"]
                    resp = requests.post(global_var.PORTS["30B"], json=payload, timeout=120)
                    answer = resp.json()['choices'][0]['message']['content']
                    
                    # ğŸ’¡ è¨˜å¾—è£œä¸Šè¨˜æ†¶å„²å­˜
                    mb.save_memory(user_input, answer) 
                    
                    return answer + "\n(âš ï¸ è¨»ï¼šåšå£«æ€è€ƒè¶…æ™‚ï¼Œæ­¤ä¹ƒ 30B ä»£ç­”)"
                except:
                    return "æŠ±æ­‰ï¼Œé€£æ¥è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
            return "ç³»çµ±ç¹å¿™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"           